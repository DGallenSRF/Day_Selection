---
title: "R Notebook"
output: html_notebook
---

Set working directory and load necessary packages.

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "H:/Projects/11000/11155/TraffStudy/DataCollection/FreewayData/Detector Data/Volume Data")

##below are a list of packages required to run the markdown file
library(tidyverse)
library(lubridate)
library(gridExtra)
library(reshape2)
library(zoo)
library(imputeTS)
library(xts)
library(dygraphs)
library(d3heatmap)
library(ggthemes)
library(plotly)

```

Load the data for March. Load each file and combine into one data set. We load and combine each file in `r getwd()`. We only want to load the files that end in "_#.csv".

```{r explore March, echo=FALSE}

dir('./March 18')

```



```{r load data for March,warning=FALSE,echo=FALSE}
path <- './March 18'

### list out all the csv files that start with TT_ and then have a number. This will avoid loading in the unwanted aggregated files or VMT files.
###'^_\\d.' returns all files that end with _some_digit.csv.
list_csv <- dir(path=path,pattern = '*_\\d.csv')

myfiles <- lapply(paste(path,'/',list_csv,sep=''),
                  function(x) read.csv(x,stringsAsFactors = FALSE))

files <- mapply(cbind,myfiles,'filename' = list_csv,SIMPLIFY = F)

dat <- bind_rows(files)

rm(myfiles,files)

#create a dataset that we will edit....
March_18_dat <- dat
```

The column names in each file are also follows. 

```{r examine columns, echo=FALSE}

colnames(March_18_dat)
```

Lets fix the column headers first. There are no headers for the first 3 columns and also there appears to be a column at the end of the data frame "X.3"

```{r suymmary of dataset}
summary(March_18_dat$X.3)
```

All NAs.... remove.

```{r remove blank last column, echo=FALSE}

March_18_dat <- March_18_dat[,!names(March_18_dat) == "X.3"]

```

Focus on the first three columns;

```{r examine first 3 rows,echo=FALSE}
str(March_18_dat[1:3])
```

Column 1 is the detector ID.<br/>
Column 2 is the metric.<br/>
Column 3 is the date.<br/>


```{r change first 3 column names, echo=FALSE}

colnames(March_18_dat)[1:3] <- c('Detector_ID','Metric','Date')

```

Now lets change the data types in the columns.

We create a correctly formatted date field from the 'Date' field.<br/>
We label the field with displays the records type i.e. Density vs Speed vs Volume as 'Metric' and change it from a string to a factor field.<br/>
We also change Detector_ID from a numeric field to a factor field.

```{r metric and Date_posixct,echo=FALSE,include=FALSE}

March_18_dat$Metric <- as.factor(March_18_dat$Metric)
March_18_dat$Date_Posixct <- as.POSIXct(March_18_dat$Date,format="%Y/%m/%d")
March_18_dat$Detector_ID <- as.factor(March_18_dat$Detector_ID)
## Check that our dates worked out. We don't want any NAs.
table(March_18_dat$Date_Posixct)

```



```{r Time field}

colnames(March_18_dat)
```


There noon and midnight are labelled as strings. The rest of the columns are labelled as times formats (in strings) but are also inconsistent in format. Lets change noon and midnight to the same format as the other times. We also want to create a uniform format across all the column names.


```{r change noon midnight names,echo=FALSE}

colnames(March_18_dat)[colnames(March_18_dat)%in%
                         c('X1.AM','X2.AM','X3.AM','X4.AM','X5.AM','X6.AM',
                           'X7.AM','X8.AM','X9.AM','X10.AM','X11.AM',
                           'X1.PM','X2.PM','X3.PM','X4.PM','X5.PM','X6.PM',
                           'X7.PM','X8.PM','X9.PM','X10.PM','X11.PM','Noon','Midnight')] <-
  c('X1.00.AM','X2.00.AM','X3.00.AM','X4.00.AM','X5.00.AM','X6.00.AM',
    'X7.00.AM','X8.00.AM','X9.00.AM','X10.00.AM','X11.00.AM',
    'X1.00.PM','X2.00.PM','X3.00.PM','X4.00.PM','X5.00.PM','X6.00.PM',
    'X7.00.PM','X8.00.PM','X9.00.PM','X10.00.PM','X11.00.PM','X00.00.AM','X00.00.PM')

March_18_dat <- March_18_dat %>% select(Detector_ID,Metric,Date,Date_Posixct,filename,everything())


```

Melt the data. We want to change the data set from a wide format to a long format. Below are the top 6 rows.

```{r melt,echo=FALSE}

March_18_melt <- melt(March_18_dat,id.vars = c('Detector_ID','Metric','Date','Date_Posixct','filename'),variable.name = "Time",value.name = 'Metric_value')

head(March_18_melt)
```



```{r Date_Time, echo=FALSE}

#remove X
March_18_melt$Time <- gsub('X','',March_18_melt$Time)

March_18_melt$Date_Time <- as.POSIXct(paste(March_18_melt$Date,March_18_melt$Time),format="%Y/%m/%d %I.%M.%p")

March_18_melt$Hour <- hour(March_18_melt$Date_Time)

```

Filter to the PM Peak hours, 2pm to 7pm.

```{r Peak Hours}

PM_Peak <- c(14:19)

March_18_melt_PM_Peak <- March_18_melt %>%
  filter(Hour>=14)%>%
  filter(Hour<=19)

```

The new filtered data set only includes data between hour `r min(March_18_melt_PM_Peak$Hour)` and hour `r max(March_18_melt_PM_Peak$Hour)`.

Lets find what detectors have bad values. We will create a list of Detector that contain records listed as '-1'. We will omit these detectors from our intial analysis. 

```{r NA values}

var <- March_18_melt_PM_Peak %>% 
  group_by(Detector_ID)%>%
  summarise(NAs =sum(Metric_value<0))%>%
  arrange(NAs)%>%
  filter(NAs==0)%>%
  droplevels()
  
no_NAs <- as.vector(var$Detector_ID)
no_NAs
```

There are `r length(no_NAs)` detectors that do not contain a -1 value.

##Time Series

Lets pick Detector 70. We want to create a variable for each day and them sum the volumes for each day.


```{r det_70,echo=FALSE}

Det_70 <-  March_18_melt_PM_Peak %>%
  filter(Detector_ID==150)%>%
  filter(Metric=="Volume")%>%
  mutate(YearDay=yday(Date_Time),
         Weekday=weekdays(Date_Time,abbreviate=TRUE))%>%
  # filter(Weekday %in% c('Tue','Wed','Thu'))%>%
  group_by(Date_Posixct)%>%
  summarise(SumVol = sum(Metric_value))

head(Det_70)
```


Now we create a time series for the data.

```{r Time Series,fig.width=9,fig.height=5,echo=FALSE}

Det_70_ts_xts <- xts(Det_70$SumVol,order.by = Det_70$Date_Posixct)

dygraph(xts(Det_70$SumVol,order.by = Det_70$Date_Posixct))%>%
  dySeries(label = 'Total Vol.')%>%
  dyRangeSelector()
```

We decompose the Time Series to extract the trend, seasonality and remainder from the time series. 

```{r decompose data, echo=FALSE}
Det_70_ts <- ts(Det_70$SumVol,frequency=3)

Det_70_ts_deomp <- decompose(Det_70_ts)

Det_70_ts_stl <- stl(Det_70_ts,s.window = 'periodic')

midweek <- c('Tuesday','Wednesday','Thursday')

plot(Det_70_ts_stl)

day_select <-  cbind(data.frame(Det_70_ts_stl$time.series[,1:3]),Date=Det_70$Date_Posixct,Weekday=weekdays(Det_70$Date_Posixct))%>%
  # mutate(Resid = abs(remainder))%>%
  filter(Weekday %in% midweek)%>%
  arrange(remainder)%>%
  print()

```


Day selection is ?.

## Correlation

Show plots of volumes by day

```{r plot values}
y <- March_18_melt_PM_Peak %>%
  mutate(Weekday = weekdays(Date_Time,abbreviate=TRUE),
         YearDay=yday(Date_Time),
         MonthDay=day(Date_Time),
         HourMin = as.numeric(format(Date_Time,"%H.%M")))%>%
  filter(Metric=='Volume')%>%
  filter(Detector_ID%in%c(147:151))%>%
  filter(Weekday %in% c('Tue','Wed','Thu'))

  ggplot(y,aes(x=Metric_value,color=as.factor(Detector_ID)))+
  geom_density()+facet_wrap(~MonthDay,nrow=4,scales = 'free_x')
```


Create detector ~ day heatmap. Each cell represents the covariance of the difference between each measurement. We have picked 100 detectors from the list for display purposes. All of the detectors shown do not contain any -1 values. 

```{r heatmap for subset,fig.width=9,echo=FALSE}

levels <- last(levels(March_18_melt_PM_Peak$Detector_ID),100)

matrix <- March_18_melt_PM_Peak %>%
  mutate(Weekday = weekdays(Date_Time,abbreviate=TRUE),
         YearDay=yday(Date_Time),
         MonthDay=day(Date_Time),
         HourMin = as.numeric(format(Date_Time,"%H"))+
           as.numeric(format(Date_Time,"%M"))/60)%>%
  filter(Metric=='Volume')%>%
  filter(Detector_ID %in% levels)%>%
  filter(Detector_ID %in% no_NAs)%>%
  group_by(Date_Posixct,Detector_ID)%>%
  arrange(Date_Time)%>%
  mutate(cumSum = cumsum(Metric_value))%>%
  mutate(correlation = lm(cumSum~HourMin)$coefficients[2],
         cov=cov(HourMin,cumSum))%>%
  arrange(Date_Posixct)


matrix_spread <- matrix%>%
  group_by(Date_Posixct,Detector_ID)%>%
  # summarise(correlation=first(correlation))%>%
  summarise(Volume=sum(Metric_value))%>%
  # summarise(cov=first(cov))%>%
  spread(Date_Posixct,Volume)


vector <- as.character(matrix_spread$Detector_ID)
matrix2 <- matrix_spread[,-1] %>% as.data.frame()
rownames(matrix2) <- vector
d3heatmap(matrix2,scale = 'row',Colv = 'as-is',colors = 'Blues')
```

Cluster Days

```{r}

day_SDev <- March_18_melt_PM_Peak %>%
  mutate(Weekday = weekdays(Date_Time,abbreviate=TRUE),
         YearDay=yday(Date_Time),
         MonthDay=day(Date_Time),
         HourMin = as.numeric(format(Date_Time,"%H.%M")))%>%
  filter(Metric=='Volume')%>%
  group_by(Detector_ID,Date_Posixct)%>%
  summarise(SumVol = sum(Metric_value))%>%
  group_by(Date_Posixct)%>%
  summarise(SDev = sd(SumVol))%>%
  mutate(weekDay=weekdays(Date_Posixct,abbreviate=TRUE))

sundays <-day_SDev$Date_Posixct[day_SDev$weekDay%in%c('Sun')]

ggplot(day_SDev) + 
  geom_point(aes(Date_Posixct,SDev)) + 
  geom_rug(aes(Date_Posixct,SDev)) + 
  geom_vline(xintercept = sundays,linetype='dotted') +
  theme_tufte(ticks = F) +
  xlab("STD of the total volume across all Detectors") + 
  ylab("Date") + 
  theme(axis.title.x = element_text(vjust=-0.5), axis.title.y = element_text(vjust=1))

```

Cumulative running total

```{r cumsum, fig.width=9}

g <- March_18_melt_PM_Peak %>%
  mutate(Weekday = weekdays(Date_Time,abbreviate=TRUE),
         YearDay=yday(Date_Time),
         MonthDay=day(Date_Time),
         HourMin = as.numeric(format(Date_Time,"%H"))+
           as.numeric(format(Date_Time,"%M"))/60)%>%
  filter(Detector_ID==4069 & Metric=='Volume')%>%
  # filter(YearDay==65 & Metric=='Volume')%>%
  # filter(Detector_ID %in% no_NAs)%>%
  # filter(Metric=='Volume')%>%
  droplevels()%>%
  group_by(YearDay)%>%
  arrange(YearDay,HourMin)%>%
  # group_by(Detector_ID,Date_Posixct)%>%
  mutate(cumSum = cumsum(Metric_value),
         lreg=lm(cumSum~HourMin)$coefficients[2],
         correlation=cor(HourMin,cumSum),
         cov=cov(HourMin,cumSum))

h <- g%>%
  group_by(Date_Posixct)%>%
  summarise(Correlation=first(correlation),
            LIN=first(lreg),
            cov=first(cov))%>%
  mutate(wday = weekdays(Date_Posixct))%>%
  arrange(Date_Posixct)
```

The below plot shows the cumulative summation of the peak hour volumes for each day in March 2018 for Detector 4069. The color scheme shows increasing covariance. Line to the bottom of the plot are Sundays and Saturdays.

```{r plot cunsum,echo=FALSE}
plot <- ggplot(g) + 
  geom_line(aes(x=HourMin,y=cumSum,group=Date_Posixct,color=cov)) + 
  # geom_rug(aes(x=HourMin,y=cumSum)) + 
  # geom_smooth(aes(x=HourMin,y=diff))+
  theme_tufte(ticks = F) +
  xlab("Hour") + 
  ylab("CumSum") + 
  theme(axis.title.x = element_text(vjust=-0.5), axis.title.y = element_text(vjust=1))  

ggplotly(plot)
```

The following plot displays straight volume across the peak hours for March for Detector 4069.

```{r plot2   volume,echo=FALSE}
plot2 <- ggplot(g) + 
  geom_line(aes(x=HourMin,y=Metric_value,group=Date_Posixct,color=cov)) + 
  # geom_rug(aes(x=HourMin,y=cumSum)) + 
  # geom_smooth(aes(x=HourMin,y=diff))+
  theme_tufte(ticks = F) +
  xlab("Hour") + 
  ylab("Volume") + 
  theme(axis.title.x = element_text(vjust=-0.5), axis.title.y = element_text(vjust=1))  

ggplotly(plot2)

```



